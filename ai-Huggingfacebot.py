import sqlite3
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters
from transformers import AutoModelForCausalLM, AutoTokenizer

# Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ API
TELEGRAM_BOT_TOKEN = "TELEGRAM_BOT_TOKEN"
HUGGINGFACE_API_KEY = "HUGGINGFACE_API_KEY"

# Ù„ÛŒØ³Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù…Ø¬Ø§Ø² (ID Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ØªÙ„Ú¯Ø±Ø§Ù…)
ALLOWED_USERS = [2016507333,35657678994]  # Ø´Ù†Ø§Ø³Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù…Ø¬Ø§Ø²

# Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ SQLite
conn = sqlite3.connect("chat_history.db", check_same_thread=False)
cursor = conn.cursor()

# Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯ÙˆÙ„ Ø°Ø®ÛŒØ±Ù‡ Ù…Ú©Ø§Ù„Ù…Ø§Øª
cursor.execute("""
    CREATE TABLE IF NOT EXISTS history (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        user_id INTEGER,
        username TEXT,
        user_message TEXT,
        ai_response TEXT,
        timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
    )
""")
conn.commit()

#Hugging Face Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ùˆ ØªÙˆÚ©Ù†Ø§ÛŒØ²Ø± Ø§Ø² 
model_name = "EleutherAI/gpt-neo-125M"  
model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=HUGGINGFACE_API_KEY)
tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=HUGGINGFACE_API_KEY)

def save_conversation(user_id, username, user_message, ai_response):
    """
   SQLite Ø°Ø®ÛŒØ±Ù‡ Ù…Ú©Ø§Ù„Ù…Ø§Øª Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ 
    """
    cursor.execute("""
        INSERT INTO history (user_id, username, user_message, ai_response)
        VALUES (?, ?, ?, ?)
    """, (user_id, username, user_message, ai_response))
    conn.commit()

def generate_response(prompt):
    """
   Hugging Face ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø§Ø² Ù…Ø¯Ù„ 
    """
    inputs = tokenizer(prompt, return_tensors="pt")
    outputs = model.generate(inputs.input_ids, max_length=100, num_return_sequences=1)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
   /start Ø¯Ø³ØªÙˆØ± : Ù¾ÛŒØ§Ù… Ø®ÙˆØ´â€ŒØ¢Ù…Ø¯Ú¯ÙˆÛŒÛŒ
    """
    await update.message.reply_text(
        "Ø³Ù„Ø§Ù…! Ù…Ù† ÛŒÚ© Ø±Ø¨Ø§Øª Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù‡Ø³ØªÙ…. Ù‡Ø± Ø³ÙˆØ§Ù„ÛŒ Ø¯Ø§Ø±ÛŒ Ø¨Ù¾Ø±Ø³. Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ØŒ Ù¾ÛŒØ§Ù… Ø¬Ø¯ÛŒØ¯ÛŒ Ù†ÙØ±Ø³Øª. ğŸ˜„"
    )

async def ask_gpt(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    username = update.message.from_user.username
    user_message = update.message.text

    # Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ú©Ø§Ø±Ø¨Ø±
    if user_id not in ALLOWED_USERS:
        await update.message.reply_text("Ù…ØªØ£Ø³ÙÙ…ØŒ Ø´Ù…Ø§ Ø§Ø¬Ø§Ø²Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÛŒÙ† Ø±Ø¨Ø§Øª Ø±Ø§ Ù†Ø¯Ø§Ø±ÛŒØ¯.")
        return

    #Hugging Face Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ù‡ Ù…Ø¯Ù„ 
    try:
        ai_response = generate_response(user_message)
    except Exception as e:
        ai_response = f"Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯Ù‡ Ø§Ø³Øª: {e}"

    # Ø°Ø®ÛŒØ±Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
    save_conversation(user_id, username, user_message, ai_response)

    # Ø§Ø±Ø³Ø§Ù„ Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±
    await update.message.reply_text(ai_response)

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
   /help Ø¯Ø³ØªÙˆØ± : Ø§Ø±Ø§Ø¦Ù‡ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ
    """
    await update.message.reply_text(
        "Ù…Ù† ÛŒÚ© Ø±Ø¨Ø§Øª Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù‡Ø³ØªÙ…! Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ Ø³ÙˆØ§Ù„Ø§ØªØª Ø±Ùˆ Ø¨Ù¾Ø±Ø³ÛŒ Ùˆ Ù…Ù† Ø¬ÙˆØ§Ø¨Øª Ø±Ùˆ Ù…ÛŒØ¯Ù….\n"
        "Ø¯Ø³ØªÙˆØ±Ø§Øª Ù…ÙˆØ¬ÙˆØ¯:\n"
        "/start - Ø´Ø±ÙˆØ¹\n"
        "/help - Ø±Ø§Ù‡Ù†Ù…Ø§"
    )

def main():
    """
    Ø§Ø¬Ø±Ø§ÛŒ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…
    """
    # Ø³Ø§Ø®Øª Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† ØªÙ„Ú¯Ø±Ø§Ù…
    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()

    # Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø³ØªÙˆØ±Ø§Øª
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, ask_gpt))

    # Ø§Ø¬Ø±Ø§ÛŒ Ø±Ø¨Ø§Øª
    print("ok")
    app.run_polling()

if __name__ == "__main__":
    main()
